# Concepts and Meaning

I think a lot of people in different fields have general intuitions of what a "concept" is. For some it might be an intuitive idea with no strick definition, and for others (perhaps with more of a computer-science/philosophy background) it might be a *very* formal idea. The layout here will follow first my general feeling. Then, I will provide a brief idea of where it fits in relative to some dominant views in the field as presented in the Stanford Encyclopedia of philosophy. I will then get into "the meat of it" with applications and implications of the ideas proposed here.

## My Approach

In keeping with my preffered style of conversing, I will start with the main punchline and then work to motivate it. 

I hope that the following sounds tautological and plainly obvious:

> "Concepts" are the things that meaning is about

What I mean by this is that concepts only have meaning in so much as they have a relationship with other concepts. I think that this principle fits with many theories, but I think it is important to explicitly draw it out. If a concept is thought of as an arbitrary symbol, then I would argue that the symbol gains "meaning" only by it's relation to other symbols. In a purely symbolic or feature based model, this could be captured in formal system through a list of propositions (e.g. **X** has wings). If a concept is a high-dimensional vector, then this is tantamount to saying "meaning" lies in the *geometry* implied by collection of a set of vectors (i.e. an operation such as an inner product could relay how similar two concepts are). The key point I mean to hone in on is that an isolated concpept is not capable of have having "meaning". In this way, strictly speaking, "concepts" don't have meaning. 

Of course one could object to my laxical use of "meaning" here, but I really only intend to use the word for it's intuitive sense. I'm only using it to give insight into my line of reasoning.

To be clear, the above formalism (with concepts as symbols, and "meaning" implicit in the relations between concepts) is agnostic about whether a theory is distributional, amodal, or embodied/grounded. In the case of a grounded theory of semantic meaning, concepts can be thought of as percptual symbols. In this case concepts are abstracted sensory impressions. The guiding intuition is that the perceptual systems give rise to constraints (or relationships) between "concepts" thus giving them meaning. As an example, the fact that cars have a color (and the fact that all concrete concepts must have a color) is a constraint that arises from the visual system. 

Given all this background the main punchline I am building up to is that

> In a formal system, meaning can be abstracted away in an association

Suppose there is a world with 3 concepts. 

Clouds --> Rain --> Sunny

> Reasoning depends on causal relations

I think that all of this so far might be pedantic, but in order to move away from what might be simply agreeing on definitions, I will admit that some openess must be had.

If "meaning" has to do with the relationship between concepts, then how to we pick the degree of abstraction at which to define concepts? One might have noticed that the description so far has been gven in terms of alread high-level concepts that we have. However, one can just as easily apply these ideas to elemtary particles and consider the forces between particles (or coupled fields if one wants to be pedantic) as the relationship. In this case, there seems to be no way to say what makes a "car" a car as opposed to a collection of trillions of atoms. It is at this point, we realize there is something deep missing from our description. why do concepts occur at the resolution that they do? In order to address this, we have to make a big jump.

I will propose a solution that might require some patience to sit with. I would argue that while meaning is deeply subjective. It is intimately tied to the affordances we have. Coffee cups have a very different meaning for humans that they do for a dog. Further, meaning is deeply tied to the person holding the concept. It is at this point we will jump out a degree and consider an agent in the environment. 

Agent in environment

We can now look at each action the agent takes. In a sense we can do the same for humans. At this point, I know some might not enjoy this particular jump, but I hope is poignancy stands out. For millenia, philosiphers have considered the nature of the will. A simple chain of reasoning might begin with asking: why did you get out of bed this morning? If it was "to get to work", then why did you want to go to work? Perhaps for some it will be to provide for their family. When we ask why someone might want to provide for their family there might a number of responses, but the essence of this my arguement will depend on a response to the effect of "because it makes me happy". Even if the response were "because it is the right thing", of course the reason to do the right thing is because while in the short term it is thought that there might be some immediate unpleasant feeling with doing the immediate task at hand, ultimately, doing the right thing leads to more joy/happyness. Of course I recognize the utilitarian arguement that seems inherent in this reasoning, but careful consideration of the above reveals it's not. Two reasons are that: 1) I have not made any claims about the morality of actions, and secondly, because I've left happiness relativly udefined. Virtue ethicists might argue virtues lead to deepest and "truest" happiness while other religions might make claims as to what brings happiness (in fact, there might even be subtypes).

The critical thing to hold on is that:

> Happyness is that thing which is sought for its own sake

By this reasoning, other things are sought to the degree to which they bring about happyness. Hopefully this at least feels subjectivly correct. And to be fair, we might not know what brings about happyness, but we still strive to maximize it. For example, supposeing happiness was like good tasting food. In order to find the best tasting food, at first we might just go about trying random foods and then noting how good they taste. After some tries, we might try to find those things which cause food to taste the best (e.g. color, shape, textures associated with good tasting food). People might develop different theories as to how the relevant properties relate to the function of interest (how good a food tastes). 


I feel that prior to advancing to the central thesis of this post, I should clarify that I am *emphatically* in support of embodied/grounded theories of cognition. I certainly think that perceptual systems are **central** to what meaning is. I just want to clarify that I think it is the perceptual systems that give rise to constraints or relationships between "concepts" thus giving them meaning.

With that clarification, my central claim can be summarized as:

> Given a system that maps $$ R^n $$  to $$R^m$$, concepts are the highly occupied regions in phase-space (i.e. attractor basins) and *meaning* arises from the degrees of freedom implicit in the systems dynamics

I dont know if that makes sense but hopefully I can help

## Embodied Theories of Semantics

Why am I such a fervent believer in embodied theories of semantics? If you aren't familiar with the discussion of what were classically called amodal theories and grounded theories of semantics, I might suggest [this]() paper as a starting reference. In brief, grounded theories emphasize that the brain's perceptual systems play a critical role in conept representation.

### Subjective Experiences Evade Description

A simple thought experiment that seems intuitvly obvious to me is the following:

> If someone was born congenitally blind (e.g. no eyes), could you explain to this person what the subjective experience of seeing *red* is?

Some people might try to play devils advocate, but I think that largely it feels that you could not. Of course analogies could be made, but I would argue that many of these depend on learned associations and don't capture much of the subjective experience. For example a perhaps more commonly considered similar question is whether there is a way for us to be sure that my experience of a color is the same as yours. We might both point to an object and call it a particular color, but it seems that there would be no way for us to be sure that we actually experience the same color. In this case I would argue assocations (like red is a *warm* color) isn't sufficient to determine the phenomenological experience. This example of how 

In this case, a generalization is recognizing that every phenomoenolgical experience (the taste of something, the sound of something, the texture of something) could never be conveyed by words alone. It *requires* a first-hand experience of the experience. 

What this tells me is that first hand experience is reqiured

## Inductive Biases

One key feature of how