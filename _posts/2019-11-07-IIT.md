---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: post
title: Consciousness and IIT
date: 2019-11-07
permalink: /posts/IIT
---
# {{ page.title }}
# Consciousness:
In having spent some time reading and thinking about ‘information theory’ ideas of consciousness, certain ideas have struck me in their salience and prescience. With the emphasis of contempory theories of consciousness honing in on why certain patterns of neuronal firing give rise to the subjective experience of consciousness, while other patters of firing do not, I think there are considerable downstream consequences with respect to semantic information. Reading about proposed necessary conditions under which subjective conscious experiences might arise has lead to a growing cycle of considering connections between the subjective experience of neurons firing, and semantic information. I hope reflect some of the unmatched salience I have read n the works of Guilo Tonini and the like. Certain ideas seem salient, and prescient, and I hope that you find the below discussion as I have in thinking about the topic.

What I hope to describe, and perhaps even make appear obvious, is a connection between the subjective consciousness experience and semantic information. 
There is much discussion on consciousness by both philosiphers, neuroscientists, psychlgy, and a slew of other branches. The perspective taken below is concerned with what David Chalmers might term “the easy question of consciousness”. To discuss consciousness, I mean that subjective experience you are experiencing at this moment. I mean that precise way in which sensory information is being abstracted to a level at which you are experiencing it. Consciousness, as used throughout this essay, is that experience you are having now that you do not have when you are in a deep and dreamless sleep.
The crux of my argument will ultimately lie on motivating information theoretic measures of consciousness, considering what the natural implications are of such theories, and motivating a testable hypothesis based on the implications

## Preliminaries:
David Chalmers is well known for phrasing the question of consciousness into a so-called easy and hard problem. A cursory description of the difference is the Hard question deals with the mechanism by which course-graining  information leads to a subjective conscious experience (akin to “why”). The easy question is more analogous to the details and empirical rules of what happens. What I am interested in is the easy question. The central question phrase in modern understanding is understanding how the information coming in from sensory neurons becomes abstracted where at some level of abstraction it becomes ‘felt’ .

To begin the discussion, I want to establish some common ground we might agree upon. First, I would argue that advanced animals have semantic knowledge. Semantic knowledge, knowledge about persons, places, things, is simply knowledge of concepts. It is important to distinguish knowledge of concepts from language, which is more analogous to a mapping of semantic knowledge to symbols, which might follow rules, and be used to communicate to other beings. I would argue that dogs have the basic semantic representations for what a ball is, what a food bowl is, what a leader is, and other concepts as well. 

To re-emphasize, I hope to isolate semantic knowledge from symbolic language. Given the difference between these items, it then seems natural to note that, by-and-large, semantic knowledge predates that ability to communicate it.

Semantic knowledge/concepts predating language, at a high level, seems evident from considerations of the question: “why are people so adept at learning language”. While animals do have communication, there is a striking advancement in the complexity and nuance of human spoken/written language compared to all other species. The relatively short period of selective pressure for our language systems begs the question of what led to this? I think viewing semantic information as a fall-out of the conscious process, which has been possessed by animals for much longer in evolutionary terms, leads us to a natural answer; the semantic concepts have always been represented in the brain with mechamisms for storage and retrieval! A;; it was lacking was a mapping of semantic concepts to phonological forms!
A word of caution: this argument might require a jump. Consciousness requires semantic retrieval
If we look around and notice the color of an object, how is it that ourmind even knows the property that is color? The answer is natural, we’ve had subjective experiences of millions of other objects of which our brain has determined the relevant co-varying attributes. What I hope to draw attention to in this discussion is exactly how hard it might be to tease apart consciousness from semantic storage and retrieval (or arguably, experience). 
An implication of what I am arguing for is that when we see a car drive by, by the act of recognizing that a car is driving by, we have retrieved the semantic information of “car” and “drive”. It is important to re-emphasize that I am not saying that we retrieve this knowledge when we say to ourselves “a car drove by”, but I am arguing that implicitly, every second of our waking experience, sensory information is being abstracted to some level until it is at a level of semantic information. I would argue that if we use the word “car” in the above situation, that is a qualitatively different subjective experience, and semantic retrieval process, than if the same person had thought that was “a blue honda civic that drove by”.  Consciousness is fundamentally interested in how the sensory inputs become abstracted. 
I hope to not be too repetitive, but I want to hone in on the idea of consciousness being best thought of with respect to “how does sensory input (or patterns of neuronal firing), enter into the subjective experience”? 
For those open to this idea already, the can likely skip the below section. I hope to address why it might be reasonable to suppose that in some relevant sense, there is a neural correlate of consciousness.
First, some might propose that consciousness is an emergent property, and is the result of millions of neurons firing and where asking the question of localization is ill-defined or not senesical. For this, there are strong counter arguments. Mainly of the 90 billion neurons in the brain, 2/3rds of them lie in the cerebellum, and while there are 4 times as many neurons in the cerebellum as in the neocortex, we know you can function well without it! Case reports of cerebellar agenesis (with no cerebellum at all) have the experience of consciousness! For all those neurons, none of them give rise to the subjective experience of consciousness. A similar argument can be made for the gut, and other autonomic systems as well. Excluding the cerebellum, one miht think that more recently evolved structures like the prefrontal cortex should contribute to the conscious experience, but again, years of lobotomies and other case reports have shown that while you lose emotional affect, the subjective experience of consciousness you and I are currently feeling is as present as ever. This argument continues for the visual cortex, temporal lobes, brainstem and many other structures. While it seems it could be distributed over all these regions, we know that these regions still fire and are active in a dreamless state (or under propofol sedation), so any theory of consciousness would be left asking what is the specific group dynamic that gives rise to the conscious experience, as having the active proper subcomponents is not sufficient. 
‘’’ to finish this conversation, I would also like to address the sensory input case ‘’’
In the above idea, if one accepts that the relevant parts of the brain need to be yolked together in the proper way, then it is natural to ask what is the mechanism by which the brain becomes yolked in the proper way? As it turns out, this question is investigated and there is a literature with current evidence for certain posterior hotspots (see et all for an excellent review citations).
I think the above arguments culminate in the ideas behind modern theories of information theoretic models of consciousness. Largely, that consciousness is ascribable to a type of information which arsies under certain conditions. 
I am not interested in how the abstracted information ultimately feels, but I think there is an intimate connection to the information that is felt, and that information which makes up semantic knowledge. 
To motivate all of this, I think it is necessary to describe, briefly, the underlying principles of IIT. After having done that, I can go on to describe some possible fall-outs which lead to ideas which can be empirically tested. 

---
## Implications of Information Theory Consciousness:
1)	All semantic information is experiential
Based off of ideas of IIT, the kind of information that our brain is adept at handling is integrated information.
2)	There is no natural distinction between concrete and abstract words
In IIT, it seems natural to define a the meaning of a word along the lines of information that is contained in and above the individual sensory input that goes into that word. For this reason, the fundamental nature and way abstract words are stored should be the same as for concrete. The reason for this 
	Plausability
In every day parlanance, it is well known that most of our vocabulary is made up of abstract words. In fact, most of the words in this exact sentence are abstract! We know that there is no computational difficulty in dealing with abstract words over concrete. Further, there is no reason to think that abstract words should be later to evolve due to this ease
3)	All words require widespread topological distribution over the neural correlates of consciousness
Since IIT predicts words 
4)	Words should have minimal mutual information with the underlying sensory information
This is more deeply connected to a notion of informational closure. In a different theory of consciousness, there is a notion of information closure. The argument here is that for something to enter the conscious experience it must have an internal representation that is compatible with the outside sensory information. This means that for the conscious experience, there must be NTIC. This is more of a constraint on the kinds of networks that can support consciousness, but doesn’t shed light onto the nature of the information abstracted
5)	The minimum neural substrate for consciousness is where language must exist
6)	Nouns, verbs, and other parts of speech have the same neural substrate
Minor points:
a)	Strictly FF NN’s will not contain any signifigant semantic information. In this way, the cerebellum should not contain semantic information, along with other areas with a similar architecture
b)	Word retrieval will always be a top down process. 
Closing:
I think that to answer the core question: why is language so natural for us? We must consider that it has had an intimate role in life-forms for millions of generations. Gestalt, we know that consciousness has been an emergent property of life, so it would seem as though we need it. 
---
The reason these core part of the language system are seldom seen is because it is impossible to get them from the underlying tasks. We are always conscious in the scanner and thus accessing semantic information. There will not be a way to dissociated the mechanisms which retrieve semantic information, because I argue they are always at play. 
I will also close, that while there may eventually be insurmountable problems with this theory or a theory which surplants it, it feels that this has to be the right avenue.
If I was to be honest, I feel this in my bones, and after all, isn’t feeling something is true all that we can ever be sure of?


