---
layout: post
title: Pre-Processing Steps
date: 2020-10-16
author: Stephen
---
I wanted to talk about how we pre-process data in the lab, and some other approaches

**Contents**
* TOC
{:toc}

## HCP Approach
The information here is taken from the reference manual for the last release of HCP data titled HCP_S1200 ([here](https://www.humanconnectome.org/storage/app/media/documentation/s1200/HCP_S1200_Release_Reference_Manual.pdf))

Some notable points are that that the resting state totals 57 minutes!

![hcp_rest](/assets/rest.png)

The other tasks that are included are below:

![tasks](/assets/tasks.png)

The HCP processing pipeline was published in neuroimage in 2013 and is titled:

> The minimal preprocessing pipelines for the Human Connoectome Project

The paper notes that most researchers should probably work with the pre-proccessed datasets to not have to deal with esoteric issues such as the "correction of gradient nonlinearity distortion in images acquired with oblique slices". Overall, there are 6 goals of the pipeline:

1. Remove spatial artifacts and distortions
2. Generate cortical surfaces, sgmentations, and myelin maps
3. Make the data easily viewable in the workbench software
4. Generate precise within-subject  cross-modal registrations
5. Handle surface and volume cross-subject registrations to standard volume and surface spaces
6. Make the data available in CIFTI format

These major goals 


To understand the preproccessing pipeline, we have to go to the WashU github page ([here](https://github.com/Washington-University/HCPpipelines)). 
